{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db13a34-e0c2-4b84-a713-fefd79d5d7df",
   "metadata": {},
   "source": [
    "# ONNX to Tensorflow Conversion\n",
    "\n",
    "## Loading an ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eabc06b-28a1-48b4-a5c9-4c0c776a3fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "import onnx\n",
    "from onnx import shape_inference, TensorProto\n",
    "from onnx import version_converter\n",
    "from onnx import numpy_helper\n",
    "import onnx.helper as helper\n",
    "\n",
    "from onnxsim import simplify\n",
    "\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28c116-8774-4e70-bd07-1b9163256ab1",
   "metadata": {},
   "source": [
    "## Tensorflow to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcacfb0-5bc9-4337-bc6d-adef76f0d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = tf.keras.saving.load_model('mobilenet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7384832-4e36-4d27-8533-0aad68bb3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f75a5-43c0-4c25-aed5-e927fa8d07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signature = [tf.TensorSpec([1, 224, 224, 3], tf.float32, name='x')]\n",
    "# Use from_function for tf functions\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(tf_model, input_signature, opset=12)\n",
    "onnx.save(onnx_model, \"mobilenet_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fb8303-dc82-456a-aef7-ac3a15110944",
   "metadata": {},
   "source": [
    "`AttributeError: 'FuncGraph' object has no attribute '_captures'`\n",
    "\n",
    "> BUG Tensorflow 2.13 / Python 3.11: [GITHUB ISSUE1](https://github.com/onnx/tensorflow-onnx/issues/2172), [GITHUB ISSUE1](https://github.com/onnx/tensorflow-onnx/issues/2180) AttributeError: 'FuncGraph' object has no attribute '_captures'. Did you mean: 'captures'?\n",
    "\n",
    "Replace the following in:\n",
    "\n",
    "* `~/.local/lib/python3.11/site-packages/tf2onnx/tf_loader.py`\n",
    "* `~/.local/lib/python3.11/site-packages/tf2onnx/convert.py`\n",
    "\n",
    "\n",
    "```python\n",
    "    #graph_captures = concrete_func.graph._captures  # pylint: disable=protected-access\n",
    "    #captured_inputs = [t_name.name for t_val, t_name in graph_captures.values()]\n",
    "\n",
    "    if hasattr(concrete_func.graph, \"captures\"):\n",
    "        graph_captures = concrete_func.graph.captures\n",
    "        captured_inputs = [t_name.name for t_val, t_name in graph_captures]\n",
    "    else:\n",
    "        graph_captures = concrete_func.graph._captures\n",
    "        captured_inputs = [t_name.name for t_val, t_name in graph_captures.values()]\n",
    "````        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb5d19-f4c5-4d2e-9224-fb716d408f1c",
   "metadata": {},
   "source": [
    "## Tensorflow Lite to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d31a2-2d7b-48ba-8500-5e8c688f3991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf2onnx.convert.from_tflite(\n",
    "    tflite_path='mobilenet_model.tflite',\n",
    "    output_path='mobilenet_model_tflite.onnx',\n",
    "    opset=12\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af63861-5b14-4e40-bf5b-424978863d60",
   "metadata": {},
   "source": [
    "## ONNX to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c1735-0e93-42ff-9de7-7a6352ef890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf model\n",
    "onnx_model = onnx.load(\"mobilenet_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2a81a-23bc-4f0d-8af8-d2f65d72f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_prep = prepare(onnx_model)\n",
    "tf_prep.export_graph('deploy_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a675e-f3dc-43e1-a41d-b805daba3da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf lite model\n",
    "onnx_lite_model = onnx.load(\"mobilenet_model_tflite.onnx\")\n",
    "onnx.checker.check_model(onnx_lite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe6927-6199-4998-9290-e02108d0fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_prep = prepare(onnx_lite_model)\n",
    "tf_prep.export_graph('deploy_lite_model')\n",
    "\n",
    "#  ValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a6193-b721-428c-9466-a311d70e1b86",
   "metadata": {},
   "source": [
    "## Generate ONNX Prototext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e7d47-d59a-4acf-ae47-cc7fb6ba9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_normal(elem, indent, file) :\n",
    "    for s in str(elem).splitlines() :\n",
    "        print(indent + s, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d250b01-5fac-42f8-aab7-02c86c6be0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_initializer(elem, indent, file) : \n",
    "    # calculate size.\n",
    "    size = 1\n",
    "    for d in elem.dims :\n",
    "        size *= d\n",
    "\n",
    "    # in the case of enough small size, output all data.\n",
    "    if (size <= 32) :\n",
    "        dump_normal(elem, indent, file)\n",
    "        return\n",
    "\n",
    "    # output metadata only, in all other cases.\n",
    "    for d in elem.dims :\n",
    "        print(indent + \"  dims: \" + json.dumps(d), file=file)\n",
    "        print(indent + \"  data_type: \" + json.dumps(elem.data_type), file=file)\n",
    "        print(indent + \"  name: \" + json.dumps(elem.name), file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a0397b-ac1d-4b5c-a725-fb9239741cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx2prototxt(onnx_path) :\n",
    "\n",
    "    # show information\n",
    "    out_path = onnx_path + \".prototxt\"\n",
    "    print(\"+ creating \" + out_path)\n",
    "    print(\"    from \" + onnx_path + \" ...\")\n",
    "\n",
    "    # load model\n",
    "    model = onnx.load(onnx_path)\n",
    "\n",
    "    # print prototxt\n",
    "    with open(out_path, \"w\") as f :\n",
    "        print(\"ir_version: \" + json.dumps(model.ir_version), file=f)\n",
    "        print(\"producer_name: \" + json.dumps(model.producer_name), file=f)\n",
    "        print(\"producer_version: \" + json.dumps(model.producer_version), file=f)\n",
    "        # print(\"domain: \" + json.dumps(model.domain), file=f)\n",
    "        print(\"model_version: \" + json.dumps(model.model_version), file=f)\n",
    "        # print(\"doc_string: \" + json.dumps(model.doc_string), file=f)\n",
    "        print(\"graph {\", file=f)\n",
    "        print(\"  name: \" + json.dumps(model.graph.name), file=f)\n",
    "\n",
    "        for e in model.graph.node :\n",
    "            print(\"  node {\", file=f)\n",
    "            dump_normal(e, \"    \",  f)\n",
    "            print(\"  }\", file=f)\n",
    "\n",
    "        for e in model.graph.initializer :\n",
    "            print(\"  initializer {\", file=f)\n",
    "            dump_initializer(e, \"    \",  f)\n",
    "            print(\"  }\", file=f)\n",
    "\n",
    "        for e in model.graph.input :\n",
    "            print(\"  input {\", file=f)\n",
    "            dump_normal(e, \"    \",  f)\n",
    "            print(\"  }\", file=f)\n",
    "\n",
    "        for e in model.graph.output :\n",
    "            print(\"  output {\", file=f)\n",
    "            dump_normal(e, \"    \",  f)\n",
    "            print(\"  }\", file=f)\n",
    "\n",
    "        print(\"}\", file=f)\n",
    "\n",
    "        for e in model.opset_import :\n",
    "            print(\"opset_import {\", file=f)\n",
    "            print(\"  version: \" + json.dumps(e.version), file=f)\n",
    "            print(\"}\", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50652068-6bb2-4644-8805-5690cc988805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_usage(script) :\n",
    "    print(\"usage: python \" + script + \" input.onnx [more.onnx ..]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9725128-f9c3-48fa-a421-4086252a635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path =\"mobilenet_model.onnx\"\n",
    "\n",
    "onnx2prototxt(onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3a71e-1e5f-4194-bee6-4333a2b71854",
   "metadata": {},
   "source": [
    "## ONNX to NovaONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8942380-28e2-4bfe-aef7-6f26dc1b7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'mobilenet_model.onnx'\n",
    "OUTPUT = 'deploy.onnx'\n",
    "SKIP_FUSE_BN = True\n",
    "SKIP_ONNX_SIM = False\n",
    "SKIP_MODIFY_IDX = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87347e5d-df32-4790-9ce7-14c41caf1e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f52f9-fd72-4220-96b8-61de1082a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each dimension of input shape must greater than zero\n",
    "onnx_model.graph.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ecdcec-582a-42b8-8730-a5da3c035bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input in onnx_model.graph.input:\n",
    "        print(input.type.tensor_type.shape.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62825ba-46ad-4238-8843-dca0f674c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opset version 8 ~ 12 supported\n",
    "onnx_model.opset_import[0].version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ce53a-8798-4d35-9903-939666bc055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Supported Layer Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7ceb3-d7e9-4f86-8078-a8cc5cbc1def",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_OP_TYPE_LIST = [\n",
    "'Abs',\n",
    "'Add',\n",
    "'AveragePool',\n",
    "'BatchNormalization',\n",
    "'Clip',\n",
    "'Conv',\n",
    "'ConvTranspose',\n",
    "'Concat',\n",
    "'Flatten',\n",
    "'Gemm',\n",
    "'GlobalAveragePool',\n",
    "'GlobalMaxPool',\n",
    "'LeakyRelu',\n",
    "'LSTM',\n",
    "'MatMul',\n",
    "'Max',\n",
    "'MaxPool',\n",
    "'MaxRoiPool',\n",
    "'Mul',\n",
    "'Pad',\n",
    "'PRelu',\n",
    "'ReduceMean',\n",
    "'Relu',\n",
    "'Resize',\n",
    "'Sigmoid',\n",
    "'Softmax',\n",
    "'Sub',\n",
    "'Tanh',\n",
    "'Transpose',\n",
    "'Upsample',\n",
    "'Reshape',\n",
    "'Slice',\n",
    "'Split',\n",
    "'Neg',\n",
    "'Sub',\n",
    "'Tanh',\n",
    "'Sqrt',\n",
    "'Exp',\n",
    "'Div',\n",
    "'Log',\n",
    "'Pow',\n",
    "'Sin',\n",
    "'Floor',\n",
    "'Round',\n",
    "'Squeeze',\n",
    "'UnSqueeze'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8bc4d6-817a-41d9-bd54-bd3795809a1c",
   "metadata": {},
   "source": [
    "### Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28482d5-5661-41b2-bc89-91faf97c4586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_attribute_to_dict(onnx_attr):\n",
    "    #print(onnx_attr)\n",
    "    if onnx_attr.HasField('name'):\n",
    "        name = getattr(onnx_attr, 'name')\n",
    "        #print(name)\n",
    "\n",
    "    if onnx_attr.HasField('t'):\n",
    "        return name, numpy_helper.to_array(getattr(onnx_attr, 't'))\n",
    "\n",
    "    for attr_type in ['f', 'i', 's']:\n",
    "        if onnx_attr.HasField(attr_type):\n",
    "            return name, getattr(onnx_attr, attr_type)\n",
    "\n",
    "    for attr_type in ['floats', 'ints', 'strings']:\n",
    "        if getattr(onnx_attr, attr_type):\n",
    "            return name, list(getattr(onnx_attr, attr_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a7413-5d8f-4a20-bbe9-0b5aaa5747b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_input_from_initializer(model : onnx.ModelProto):\n",
    "    \"\"\"\n",
    "    Currently onnx.shape_inference doesn't use the shape of initializers, so add\n",
    "    that info explicitly as ValueInfoProtos.\n",
    "    Mutates the model.\n",
    "    Args:\n",
    "        model: The ModelProto to update.\n",
    "    \"\"\"\n",
    "    # All (top-level) constants will have ValueInfos before IRv4 as they are all inputs\n",
    "    if model.ir_version < 4:\n",
    "        return\n",
    "\n",
    "    def add_const_value_infos_to_graph(graph : onnx.GraphProto):\n",
    "        inputs = {i.name for i in graph.input}\n",
    "        existing_info = {vi.name: vi for vi in graph.input}\n",
    "        for init in graph.initializer:\n",
    "            # Check it really is a constant, not an input\n",
    "            if init.name in inputs:\n",
    "                continue\n",
    "\n",
    "            # The details we want to add\n",
    "            elem_type = init.data_type\n",
    "            shape = init.dims\n",
    "\n",
    "            # Get existing or create new value info for this constant\n",
    "            vi = existing_info.get(init.name)\n",
    "            if vi is None:\n",
    "                vi = graph.input.add()\n",
    "                vi.name = init.name\n",
    "\n",
    "            # Even though it would be weird, we will not overwrite info even if it doesn't match\n",
    "            tt = vi.type.tensor_type\n",
    "            if tt.elem_type == onnx.TensorProto.UNDEFINED:\n",
    "                tt.elem_type = elem_type\n",
    "            if not tt.HasField(\"shape\"):\n",
    "                # Ensure we set an empty list if the const is scalar (zero dims)\n",
    "                tt.shape.dim.extend([])\n",
    "                for dim in shape:\n",
    "                    tt.shape.dim.add().dim_value = dim\n",
    "\n",
    "        # Handle subgraphs\n",
    "        for node in graph.node:\n",
    "            for attr in node.attribute:\n",
    "                # Ref attrs refer to other attrs, so we don't need to do anything\n",
    "                if attr.ref_attr_name != \"\":\n",
    "                    continue\n",
    "\n",
    "                if attr.type == onnx.AttributeProto.GRAPH:\n",
    "                    add_const_value_infos_to_graph(attr.g)\n",
    "                if attr.type == onnx.AttributeProto.GRAPHS:\n",
    "                    for g in attr.graphs:\n",
    "                        add_const_value_infos_to_graph(g)\n",
    "\n",
    "    return add_const_value_infos_to_graph(model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b46ab-4e18-40bf-8258-d88a77f16651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplaceUpsampleWithResize(onnx_model):\n",
    "\n",
    "    graph = onnx_model.graph\n",
    "\n",
    "    for i in range(len(graph.node)):\n",
    "        if graph.node[i].op_type == 'Upsample':\n",
    "            old_node = graph.node[i]\n",
    "            roi = numpy_helper.from_array(np.empty([0], dtype=np.float32), old_node.name + \"_roi\")\n",
    "            onnx_model.graph.initializer.append(roi)\n",
    "            roi_value_info = helper.make_tensor_value_info(old_node.name + \"_roi\", onnx.TensorProto.FLOAT, [0])\n",
    "            onnx_model.graph.value_info.append(roi_value_info)\n",
    "            inputs = [old_node.input[0], old_node.name + \"_roi\", old_node.input[1]]\n",
    "            mode_string = ''\n",
    "            for attr in graph.node[i].attribute:\n",
    "                if attr.name == 'mode':\n",
    "                    mode_string = attr.s\n",
    "            new_node = onnx.helper.make_node(\n",
    "                \"Resize\",\n",
    "                coordinate_transformation_mode=\"asymmetric\",\n",
    "                cubic_coeff_a=-0.75,\n",
    "                mode=mode_string,\n",
    "                nearest_mode=\"floor\",\n",
    "                inputs=inputs,\n",
    "                outputs=old_node.output\n",
    "            )\n",
    "            graph.node.remove(old_node)\n",
    "            graph.node.insert(i, new_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af37d01-3390-48ee-98fe-0466b172d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_shapes(onnx_model):\n",
    "    names = []\n",
    "    for input_tensor in onnx_model.graph.input:\n",
    "        names.append(input_tensor.name)\n",
    "    for output_tensor in onnx_model.graph.output:\n",
    "        names.append(output_tensor.name)\n",
    "    for init_tensor in onnx_model.graph.initializer:\n",
    "        names.append(init_tensor.name)\n",
    "    for value in onnx_model.graph.value_info:\n",
    "        names.append(value.name)\n",
    "\n",
    "    for node in onnx_model.graph.node:\n",
    "        outputs = node.output\n",
    "        for output in outputs:\n",
    "            if output not in names:\n",
    "                assert False, \"Shape checking error. Node: %s Type: %s, cannot get output shape, please check the attribute.\" % (node.name, node.op_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e15728-1e42-4584-b2f4-c35e1c7b854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Constant_to_initializer(onnxmodel):\n",
    "    graph = onnxmodel.graph\n",
    "    delete = []\n",
    "    for i in range(len(graph.node)):\n",
    "        if graph.node[i].op_type==\"Constant\":\n",
    "            # data = np.frombuffer(graph.node[i].attribute[0].t.raw_data, dtype=np.float32)\n",
    "            p_t = helper.make_tensor(graph.node[i].output[0], onnx.TensorProto.FLOAT, dims = 0, vals=graph.node[i].attribute[0].t.raw_data, raw=True)\n",
    "            delete.append(graph.node[i])\n",
    "            graph.initializer.insert(0, p_t)\n",
    "    for oldnode in delete:\n",
    "        graph.node.remove(oldnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4779277-370a-43fd-8869-2fbb1718c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_layer_dix(graph):\n",
    "    outputs = graph.output\n",
    "    outputs_dict = {}\n",
    "    for i, output in enumerate(outputs):\n",
    "        for j, node in enumerate(graph.node):\n",
    "            if output.name in node.output:\n",
    "                # output_idx : node_idx, layer_idx\n",
    "                outputs_dict[i] = [j, j]\n",
    "\n",
    "    for i in range(len(outputs_dict)):\n",
    "        min_index = i  \n",
    "        # find min_index\n",
    "        for j in range(i+1, len(outputs_dict)):\n",
    "            if outputs_dict[j][1] < outputs_dict[min_index][1]:\n",
    "                min_index = j\n",
    "\n",
    "        if min_index != i:\n",
    "                # exchange layer idx\n",
    "                for k, attr in enumerate(graph.node[outputs_dict[i][0]].attribute):\n",
    "                    if attr.name == 'layer_idx':\n",
    "                        new_layer_idx = onnx.helper.make_attribute(\"layer_idx\", outputs_dict[min_index][1])\n",
    "                        del graph.node[outputs_dict[i][0]].attribute[k]\n",
    "                        graph.node[outputs_dict[i][0]].attribute.extend([new_layer_idx])\n",
    "                        break\n",
    "\n",
    "                for k, attr in enumerate(graph.node[outputs_dict[min_index][0]].attribute):\n",
    "                    if attr.name == 'layer_idx':\n",
    "                        new_layer_idx = onnx.helper.make_attribute(\"layer_idx\", outputs_dict[i][1])\n",
    "                        del graph.node[outputs_dict[min_index][0]].attribute[k]\n",
    "                        graph.node[outputs_dict[min_index][0]].attribute.extend([new_layer_idx])\n",
    "                        break\n",
    "\n",
    "                # if graph.node[1].attribute\n",
    "                outputs_dict[i][1], outputs_dict[min_index][1] = outputs_dict[min_index][1], outputs_dict[i][1]\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f85a1-3148-4596-a7ef-25b2247be29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nova_onnx(in_model_path, out_model_path, skip_fuse_bn, skip_onnx_sim, skip_modify_idx):\n",
    "    # load model\n",
    "    onnx_model = onnx.load(in_model_path)\n",
    "\n",
    "    if onnx_model.producer_name == 'Novatek NovaOnnx Converter' or onnx_model.producer_name == 'Novatek Caffe2Onnx Converter':\n",
    "        print(\"INFO :: This model is already a nova onnx model, skip the conversion process...\")\n",
    "        return\n",
    "    \n",
    "    # check input shape\n",
    "    for input in onnx_model.graph.input:\n",
    "        input_shape = input.type.tensor_type.shape.dim\n",
    "        for d in input_shape:\n",
    "            if d.dim_value <= 0:\n",
    "                assert (False), \"ERROR :: Each dimension of input shape must greater than zero, illegal input name = %s\"% input.name\n",
    "    Constant_to_initializer(onnx_model)\n",
    "    # convert model\n",
    "    add_input_from_initializer(onnx_model)\n",
    "    \n",
    "    has_custom_op = 0\n",
    "    for node in onnx_model.graph.node:\n",
    "        if node.domain != '' and node.domain != 'ai.onnx':\n",
    "            has_custom_op = 1\n",
    "    if has_custom_op == 1:\n",
    "\n",
    "        #get all value_info and output name\n",
    "        tensor_names = []\n",
    "        for vi in onnx_model.graph.value_info:\n",
    "            tensor_names.append(vi.name)\n",
    "        for output in onnx_model.graph.output:\n",
    "            tensor_names.append(output.name)\n",
    "        \n",
    "        # Add missing tensor_value_info (fake shape)\n",
    "        for i in range(len(onnx_model.graph.node)):\n",
    "            for output in onnx_model.graph.node[i].output:\n",
    "                if output not in tensor_names:\n",
    "                    if onnx_model.graph.node[i].op_type == \"Gemm\" or onnx_model.graph.node[i].op_type == \"Flatten\":\n",
    "                        fake_value_info = helper.make_tensor_value_info(output, TensorProto.FLOAT, [-1,-1])\n",
    "                    else:\n",
    "                        fake_value_info = helper.make_tensor_value_info(output, TensorProto.FLOAT, [-1,-1,-1,-1])\n",
    "                    tensor_names.append(output)\n",
    "                    onnx_model.graph.value_info.append(fake_value_info)\n",
    "    \n",
    "    else:\n",
    "        # convert model to opset 12\n",
    "        if onnx_model.opset_import[0].version != 12:\n",
    "            if onnx_model.opset_import[0].version > 12 or onnx_model.opset_import[0].version < 8:\n",
    "                assert (False), \": Opset version of the input model is %d, novaonnx only supports Opset version 8 ~ 12.\"% onnx_model.opset_import[0].version\n",
    "            print(\"WARNING :: Opset version of the input model is {}, novaonnx support Opset version 12.\".format(onnx_model.opset_import[0].version))\n",
    "            print(\"INFO :: Conversion from Opset version {} to Opset version 12.\".format(onnx_model.opset_import[0].version))\n",
    "            onnx_model = version_converter.convert_version(onnx_model, 12)\n",
    "            \n",
    "            #version_converter can not convert upsample(deprecated in opset 12), convert it to resize \n",
    "            ReplaceUpsampleWithResize(onnx_model)\n",
    "        \n",
    "        if skip_onnx_sim:\n",
    "            onnx_model = shape_inference.infer_shapes(onnx_model)\n",
    "            check_shapes(onnx_model)\n",
    "        else:\n",
    "            # apply onnx simplify\n",
    "            onnx_model, check = simplify(onnx_model, skip_fuse_bn = skip_fuse_bn)\n",
    "\n",
    "            assert check, \"WARNING :: Simplified ONNX model could not be validated\"\n",
    "            \n",
    "        for i in range(len(onnx_model.graph.node)):\n",
    "            if onnx_model.graph.node[i].op_type not in SUPPORTED_OP_TYPE_LIST:\n",
    "                print(\"WARNING :: Unsupported Layer Type \", onnx_model.graph.node[i].op_type)\n",
    "\n",
    "    graph = onnx_model.graph\n",
    "\n",
    "        \n",
    "    init_name_list = []\n",
    "    for initializer in graph.initializer:\n",
    "        init_name_list.append(initializer.name)\n",
    "    \n",
    "    name_dict = {}\n",
    "            \n",
    "    #modify Conv weight name\n",
    "    for i in range(len(graph.node)):\n",
    "        if graph.node[i].op_type == 'Conv':\n",
    "            if graph.node[i].input[1] in init_name_list:\n",
    "                name_dict.setdefault(graph.node[i].input[1], graph.node[i].op_type + \"_\" + graph.node[i].input[1] + \"_W\")\n",
    "                graph.node[i].input[1] = graph.node[i].op_type + \"_\" + graph.node[i].input[1] + \"_W\"\n",
    "            if len(graph.node[i].input) > 2:\n",
    "                if graph.node[i].input[2] in init_name_list:\n",
    "                    name_dict.setdefault(graph.node[i].input[2],  graph.node[i].op_type + \"_\" + graph.node[i].input[2] + \"_B\")\n",
    "                    graph.node[i].input[2] = graph.node[i].op_type + \"_\" + graph.node[i].input[2] + \"_B\"\n",
    "\n",
    "      \n",
    "        #modify output tensor_name to (node_name)_Y\n",
    "        for k in range(len(graph.node[i].input)):\n",
    "            if graph.node[i].input[k] in name_dict:\n",
    "                graph.node[i].input[k] = name_dict[graph.node[i].input[k]]\n",
    "        for l in range(len(graph.node[i].output)):\n",
    "            name_dict.setdefault(graph.node[i].output[l], graph.node[i].op_type + \"_\" + graph.node[i].output[l] + \"_Y\")\n",
    "            graph.node[i].output[l] = graph.node[i].op_type + \"_\" + graph.node[i].output[l] + \"_Y\"\n",
    "\n",
    "        # Add layer_id attribute for each node\n",
    "        new_attr = helper.make_attribute(\"layer_idx\", i)\n",
    "        graph.node[i].attribute.append(new_attr)\n",
    "        \n",
    "        #modify Conv weight name\n",
    "        if graph.node[i].op_type == 'AveragePool' or graph.node[i].op_type == 'MaxPool':\n",
    "            new_attr = helper.make_attribute(\"pool_at_pad\", 1)\n",
    "            graph.node[i].attribute.append(new_attr)\n",
    "\n",
    "    #print(graph.value_info)\n",
    "    #modify graph output tensor_name to (node_name)_Y\n",
    "    for m in range(len(graph.output)):\n",
    "        if graph.output[m].name in name_dict:\n",
    "            graph.output[m].name = name_dict[graph.output[m].name]\n",
    "            \n",
    "    #modify value info name\n",
    "    for n in range(len(graph.value_info)):\n",
    "        if graph.value_info[n].name in name_dict:\n",
    "            graph.value_info[n].name = name_dict[graph.value_info[n].name]\n",
    "\n",
    "    #modify input name\n",
    "    for o in range(len(graph.input)):\n",
    "        if graph.input[o].name in name_dict:\n",
    "            graph.input[o].name = name_dict[graph.input[o].name] \n",
    "            \n",
    "    #modify initializer name\n",
    "    for p in range(len(graph.initializer)):\n",
    "        if graph.initializer[p].name in name_dict:\n",
    "            graph.initializer[p].name = name_dict[graph.initializer[p].name] \n",
    "    \n",
    "    if not skip_modify_idx:\n",
    "        graph = modify_layer_dix(graph)\n",
    "\n",
    "    onnx_model.producer_name = 'Novatek NovaOnnx Converter'\n",
    "    onnx_model.producer_version = '1.0'\n",
    "    onnx.save(onnx_model, out_model_path)\n",
    "    print(\"INFO :: Converted to NOVA ONNX!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a29a6-a62a-4a3a-a4da-2ecbf2215215",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_nova_onnx(INPUT, OUTPUT, SKIP_FUSE_BN, SKIP_ONNX_SIM, SKIP_MODIFY_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed47fd-e833-4d8a-866e-0fae5475ac98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d317daec-fa18-4b6c-9193-14fea05fab7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
